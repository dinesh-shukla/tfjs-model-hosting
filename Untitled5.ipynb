{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjm2uj/CnmUDKku2DsLnWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinesh-shukla/tfjs-model-hosting/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDKuoDZIE7nY",
        "outputId": "2c736e7a-4a6b-4f51-f21a-54a76af4c275"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3EJP7nLvC_FT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, jaccard_score, accuracy_score\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dy_dx(x):\n",
        "    return 2*x"
      ],
      "metadata": {
        "id": "DUF3fMV9DCX_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dy_dx(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuEsaXVxDMcL",
        "outputId": "e6a5d7ee-7de4-4b21-d163-2b6307d45c3c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.0, requires_grad = True)"
      ],
      "metadata": {
        "id": "p7awHn3cFLHp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1Eo8PD_G1AJ",
        "outputId": "7c9f8e84-efcd-4b44-dcc3-adfd313c3a60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3., requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**2"
      ],
      "metadata": {
        "id": "CXI7f1JAG2Ox"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf_bKi16G4TV",
        "outputId": "92ae9cdf-5d17-4d98-ccbd-35ffeb1db226"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "lR07R5G_G9To"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPBwshejHApv",
        "outputId": "4263cf72-e8fc-4808-d633-9054319b8a3d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inputs\n",
        "x = torch.tensor(6.7)  # Input feature\n",
        "y = torch.tensor(0.0)  # True label (binary)\n",
        "\n",
        "w = torch.tensor(1.0)  # Weight\n",
        "b = torch.tensor(0.0)  # Bias"
      ],
      "metadata": {
        "id": "nF6Mq5cRhRIT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(y_pred, y_tar):\n",
        "  # prevention log(0)\n",
        "  pred = torch.clamp(y_pred, 1e-8 , 1 - 1e-8)\n",
        "  return -(y_tar*torch.log(y_pred) + (1 - y_tar)*torch.log(1 - y_pred))"
      ],
      "metadata": {
        "id": "ODVYZ7cgfmm2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  forward pass\n",
        "y_pred = torch.sigmoid(w*x + b)\n",
        "loss = binary_cross_entropy(y_pred, y)"
      ],
      "metadata": {
        "id": "YPFy8RzHhYFE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ1Fv5VIhpre",
        "outputId": "354597af-0e3b-4f39-a231-d0195c2102bf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.7012)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(6.7)\n",
        "y = torch.tensor(0.0)"
      ],
      "metadata": {
        "id": "esEtrWn_mAmm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "b = torch.tensor(0.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "gvr7gP5wl9qB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = torch.sigmoid(w * x + b)"
      ],
      "metadata": {
        "id": "akofTSZtmFYB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc6OC7n0meSD",
        "outputId": "e168e57a-f73c-4cf6-8758-79f3d4122d3f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9988, grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = binary_cross_entropy(y_pred, y)\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "lXzdY8Jmm7UI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSUy5rc3nli9",
        "outputId": "c1e0d753-52f7-4129-822b-4c0abc63784e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.6918)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nzBX5J3nm0_",
        "outputId": "9720541b-0646-4153-9095-851b12570f97"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9988)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "jUL1wlnGvjLB",
        "outputId": "ee52742b-5c95-46ce-a1c5-d6f48c1be6a5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-369af3f9-06f6-46c7-8f6d-13edff5fc2cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-369af3f9-06f6-46c7-8f6d-13edff5fc2cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-369af3f9-06f6-46c7-8f6d-13edff5fc2cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-369af3f9-06f6-46c7-8f6d-13edff5fc2cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8784b0f1-6b83-4478-b229-6a84e462a114\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8784b0f1-6b83-4478-b229-6a84e462a114')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8784b0f1-6b83-4478-b229-6a84e462a114 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4RlfVykwFQz",
        "outputId": "1484dcf1-6a73-494d-b736-303fe0f0b6c1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['id', 'Unnamed: 32'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "wPqpOBsewVXA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size = 0.2)"
      ],
      "metadata": {
        "id": "ZPogV0pQxUU7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "n2RRDtuFyRPn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijjyNxy31B1g",
        "outputId": "1688e281-cb7d-483d-ba5e-77ba64b88e60"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.80629006,  1.45951651, -1.79797378, ..., -1.78180231,\n",
              "         0.25954277,  0.89108358],\n",
              "       [-0.83494961,  3.4248443 , -0.87852904, ..., -1.31243086,\n",
              "         0.02203722, -0.58048252],\n",
              "       [-0.20890664, -1.24044704, -0.21222385, ...,  0.30550909,\n",
              "         0.53259336,  0.54878086],\n",
              "       ...,\n",
              "       [-0.13378148, -0.3310105 , -0.17997677, ..., -0.84071412,\n",
              "        -0.8843615 , -0.74436275],\n",
              "       [-1.127103  , -1.04674887, -1.13005623, ..., -1.37856814,\n",
              "         1.06576907, -0.18168867],\n",
              "       [-0.97685269,  0.25480836, -0.93052745, ..., -0.43716725,\n",
              "        -0.47236208,  0.19920701]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "ZWj0Qej61HhU",
        "outputId": "d6b5113a-1649-45b5-ec8f-6507b8ca5ce7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "538    B\n",
              "232    B\n",
              "482    B\n",
              "47     M\n",
              "319    B\n",
              "      ..\n",
              "341    B\n",
              "256    M\n",
              "149    B\n",
              "60     B\n",
              "269    B\n",
              "Name: diagnosis, Length: 455, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>455 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)"
      ],
      "metadata": {
        "id": "8ECbxIl_1TXU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3GNn5wu3nZC",
        "outputId": "91f22ed8-28e9-45ae-dac1-256fb45e41e2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-_PVbs950pj",
        "outputId": "2da76a04-92fb-4446-dea3-a2e5c4c5d426"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.80629006,  1.45951651, -1.79797378, ..., -1.78180231,\n",
              "         0.25954277,  0.89108358],\n",
              "       [-0.83494961,  3.4248443 , -0.87852904, ..., -1.31243086,\n",
              "         0.02203722, -0.58048252],\n",
              "       [-0.20890664, -1.24044704, -0.21222385, ...,  0.30550909,\n",
              "         0.53259336,  0.54878086],\n",
              "       ...,\n",
              "       [-0.13378148, -0.3310105 , -0.17997677, ..., -0.84071412,\n",
              "        -0.8843615 , -0.74436275],\n",
              "       [-1.127103  , -1.04674887, -1.13005623, ..., -1.37856814,\n",
              "         1.06576907, -0.18168867],\n",
              "       [-0.97685269,  0.25480836, -0.93052745, ..., -0.43716725,\n",
              "        -0.47236208,  0.19920701]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icY4nBs6P2mE",
        "outputId": "0b671c1a-2390-43da-9548-7bb99d81df6a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(455, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor =  torch.from_numpy(x_train).float()\n",
        "X_test_tensor = torch.from_numpy(x_test).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "y_test_tensor = torch.from_numpy(y_test).float()"
      ],
      "metadata": {
        "id": "81owMUrw5Ulw"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TrEHVIl_sZF",
        "outputId": "5d13a5ed-d6b1-4936-99f3-93040979fc37"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([455, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHWv5yHE_vpc",
        "outputId": "af9b9c6f-3e14-4200-b3ee-b178ab521521"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([455])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# simple NN"
      ],
      "metadata": {
        "id": "VumjNk74Ag6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_NN():\n",
        "  def __init__(self, x):\n",
        "    self.weight = torch.rand(x.shape[1], 1, dtype=torch.float, requires_grad=True) # weight dim = input - 30 * 1\n",
        "    self.bias   = torch.rand(1, dtype=torch.float, requires_grad=True) # bias dim 1\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = torch.matmul(x, self.weight) + self.bias\n",
        "    y_pred = torch.sigmoid(z)\n",
        "    return y_pred\n",
        "\n",
        "  def loss_function(self, y_pred, y_tar):\n",
        "    y_pred = torch.clamp(y_pred, 1e-7 , 1 - 1e-7)\n",
        "    return -(y_tar*torch.log(y_pred) + (1 - y_tar)*torch.log(1 - y_pred)).mean()\n"
      ],
      "metadata": {
        "id": "wtKGHHVA59ol"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_NN_V1(nn.Module):\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(num_features, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  def forward(self, features):\n",
        "    out = self.linear(features)\n",
        "    out = self.sigmoid(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "WnPEWQA4AgJU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_NN_V2(nn.Module):\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(num_features, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(3, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, features):\n",
        "    out = self.network(features)\n",
        "    return out"
      ],
      "metadata": {
        "id": "9RPv73PcFPSg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_1 = torch.rand(10, 5)\n",
        "model_V2 = Model_NN_V2(features_1.shape[1])\n",
        "model_V2(features_1)\n",
        "summary(model_V2, input_size=(30, 5))\n",
        "model_V2.network[0].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QviMgrLqFu-l",
        "outputId": "9ce0985b-1fea-437a-a11c-f6223d00dd3c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.3762, -0.2605, -0.1744, -0.2626,  0.3408],\n",
              "        [ 0.0313, -0.1493,  0.2435, -0.2505, -0.4417],\n",
              "        [-0.3548, -0.0067, -0.4195, -0.2371,  0.0844]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "mXUkgV6ETbYS"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "8kO1EzTN-uOT"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model_NN(X_train_tensor)\n",
        "for epoch in range(epochs):\n",
        "  y_pred = model.forward(X_train_tensor)\n",
        "  loss = model.loss_function(y_pred, y_train_tensor)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    model.weight -= learning_rate * model.weight.grad\n",
        "    model.bias -= learning_rate * model.bias.grad\n",
        "\n",
        "  model.weight.grad.zero_()\n",
        "  model.bias.grad.zero_()\n",
        "  print(f\"loss in epoch{epoch + 1}: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxxrahbMUmSR",
        "outputId": "fa42b347-dfc6-4eb2-d161-de374ca2df92"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch1: 3.689507246017456\n",
            "loss in epoch2: 3.5766334533691406\n",
            "loss in epoch3: 3.4596002101898193\n",
            "loss in epoch4: 3.339325189590454\n",
            "loss in epoch5: 3.2122857570648193\n",
            "loss in epoch6: 3.0758814811706543\n",
            "loss in epoch7: 2.936668872833252\n",
            "loss in epoch8: 2.793374538421631\n",
            "loss in epoch9: 2.647321939468384\n",
            "loss in epoch10: 2.4978744983673096\n",
            "loss in epoch11: 2.347095012664795\n",
            "loss in epoch12: 2.195039749145508\n",
            "loss in epoch13: 2.041353940963745\n",
            "loss in epoch14: 1.8901795148849487\n",
            "loss in epoch15: 1.7407195568084717\n",
            "loss in epoch16: 1.5945465564727783\n",
            "loss in epoch17: 1.4594173431396484\n",
            "loss in epoch18: 1.3372780084609985\n",
            "loss in epoch19: 1.229355812072754\n",
            "loss in epoch20: 1.1365966796875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6INWDvBHbwl8",
        "outputId": "0d5614f5-1102-40d0-fb61-784b07e781ca"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1621], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRjUXg-bbxOm",
        "outputId": "4a6246e5-55e5-402c-eac3-7f743ac798a4"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0383],\n",
              "        [ 0.4338],\n",
              "        [ 0.2943],\n",
              "        [ 0.1390],\n",
              "        [ 0.0525],\n",
              "        [ 0.1152],\n",
              "        [ 0.3293],\n",
              "        [-0.0434],\n",
              "        [-0.1151],\n",
              "        [-0.0045],\n",
              "        [-0.2892],\n",
              "        [ 0.6004],\n",
              "        [ 0.5781],\n",
              "        [-0.0353],\n",
              "        [ 0.2057],\n",
              "        [ 0.1537],\n",
              "        [-0.1955],\n",
              "        [ 0.0425],\n",
              "        [ 0.2084],\n",
              "        [-0.1682],\n",
              "        [-0.3830],\n",
              "        [ 0.5305],\n",
              "        [ 0.1754],\n",
              "        [ 0.0466],\n",
              "        [ 0.3233],\n",
              "        [-0.3741],\n",
              "        [ 0.3596],\n",
              "        [ 0.0032],\n",
              "        [-0.0780],\n",
              "        [ 0.1799]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model.forward(X_train_tensor)\n",
        "  y_pred = (y_pred > 0.9).float()\n",
        "  accuraccy = (y_pred == y_train_tensor).float().mean()\n",
        "  print(f\"accuraccy: {accuraccy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt_X4q5kb0u0",
        "outputId": "4d5fabf3-c150-4ff2-9105-b0290ec2e620"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuraccy: 0.5977345705032349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function_V1 = nn.BCELoss()\n",
        "model_V1 = Model_NN_V1(X_train_tensor.shape[1])\n",
        "optimizer = torch.optim.SGD(model_V1.parameters(), lr = learning_rate)\n",
        "for epoch in range(epochs):\n",
        "  y_pred = model_V1(X_train_tensor)\n",
        "  loss = loss_function_V1(y_pred, y_train_tensor.view(-1, 1))\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(f\"loss in epoch{epoch + 1}: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFpnkZ53AW30",
        "outputId": "59732a42-9e96-4455-eba2-6e7cf2bff300"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in epoch1: 0.9537197947502136\n",
            "loss in epoch2: 0.6454175114631653\n",
            "loss in epoch3: 0.4927574694156647\n",
            "loss in epoch4: 0.41273999214172363\n",
            "loss in epoch5: 0.3632909655570984\n",
            "loss in epoch6: 0.329202264547348\n",
            "loss in epoch7: 0.30399829149246216\n",
            "loss in epoch8: 0.2844405174255371\n",
            "loss in epoch9: 0.26871660351753235\n",
            "loss in epoch10: 0.25572773814201355\n",
            "loss in epoch11: 0.24476657807826996\n",
            "loss in epoch12: 0.23535571992397308\n",
            "loss in epoch13: 0.22716067731380463\n",
            "loss in epoch14: 0.21993950009346008\n",
            "loss in epoch15: 0.2135125994682312\n",
            "loss in epoch16: 0.2077435702085495\n",
            "loss in epoch17: 0.2025267779827118\n",
            "loss in epoch18: 0.19777895510196686\n",
            "loss in epoch19: 0.19343358278274536\n",
            "loss in epoch20: 0.189436674118042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model_V1(X_train_tensor)\n",
        "  y_pred = (y_pred > 0.5).float()\n",
        "  accuraccy = (y_pred == y_train_tensor).float().mean()\n",
        "  print(f\"accuraccy: {accuraccy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9iMT1HXEoN-",
        "outputId": "3cf7ecef-3b69-48af-dc2c-33936a3d4bf7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuraccy: 0.5365390777587891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir, label_dir, transform = None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_dir (str): Path to the data directory.\n",
        "            label_dir (str): Path to the label directory.\n",
        "            transform (callable, optional): Transform to apply to both images and labels.\n",
        "        \"\"\"\n",
        "        self.data_dir = data_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.data_files = []\n",
        "        self.label_files = []\n",
        "        for state in os.listdir(data_dir):\n",
        "            state_data_path = os.path.join(data_dir, state)\n",
        "            state_label_path = os.path.join(label_dir, state)\n",
        "\n",
        "            if os.path.isdir(state_data_path) and os.path.isdir(state_label_path):\n",
        "                for district in os.listdir(state_data_path):\n",
        "                    district_data_path = os.path.join(state_data_path, district)\n",
        "                    district_label_path = os.path.join(state_label_path, district)\n",
        "\n",
        "                    if os.path.isdir(district_data_path) and os.path.isdir(district_label_path):\n",
        "                        for data_file in os.listdir(district_data_path):\n",
        "                            data_path = os.path.join(district_data_path, data_file)\n",
        "                            label_path = os.path.join(district_label_path, data_file)\n",
        "\n",
        "                            if os.path.exists(label_path):\n",
        "                                self.data_files.append(data_path)\n",
        "                                self.label_files.append(label_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_path = self.data_files[idx]\n",
        "        label_path = self.label_files[idx]\n",
        "\n",
        "        data_image = Image.open(data_path).convert(\"RGB\")\n",
        "        label_image = Image.open(label_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            data_image = self.transform(data_image)\n",
        "            label_image = self.transform(label_image)\n",
        "\n",
        "        return data_image, label_image\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_dir = \"DATA\"\n",
        "    label_dir = \"LABEL\"\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    dataset = CustomDataset(data_dir=data_dir, label_dir=label_dir, transform=transform)\n",
        "\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    # resolving class imbalance\n",
        "    # count_class = [len(np.where(np.array(trainset.targets) == t)[0]) for t in np.unique(trainset.targets)] # [729684234, 23717622]\n",
        "    # weights = 1. / torch.tensor(count_class, dtype=torch.float) # tensor([1.3705e-09, 4.2163e-08])\n",
        "    # samples_weights = [0]*len(trainset) # 2874\n",
        "\n",
        "    # sampler = WeightedRandomSampler(weights = samples_weights, num_samples = len(samples_weights), replacement=True)\n",
        "    # trainloader = DataLoader(train_subset, batch_size = BATCH_SIZE, sampler = sampler, shuffle = False, pin_memory = False, num_workers = 2, drop_last=True)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size = 8, shuffle = True, num_workers = 4)\n",
        "    test_loader = DataLoader(test_dataset, batch_size = 8, shuffle = False, num_workers = 4)\n",
        "\n",
        "    print(\"Training DataLoader:\")\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        print(f\"Batch {batch_idx + 1}:\")\n",
        "        print(f\"Data Shape: {data.shape}, Labels Shape: {labels.shape}\")\n",
        "        break  # Test one batch\n",
        "\n",
        "    print(\"\\nTesting DataLoader:\")\n",
        "    for batch_idx, (data, labels) in enumerate(test_loader):\n",
        "        print(f\"Batch {batch_idx + 1}:\")\n",
        "        print(f\"Data Shape: {data.shape}, Labels Shape: {labels.shape}\")\n",
        "        break  # Test one batch\n",
        "\n",
        "\n",
        "    # training_size = len(trainloader)\n",
        "    # val_size = len(valloader)\n",
        "    # dataset_size = len(dataset)\n",
        "\n",
        "    # for img1, img2, cm in trainloader:\n",
        "    #   img1 = img1.numpy()[1].transpose(2,1,0)\n",
        "    #   img2 = img2.numpy()[1].transpose(2,1,0)\n",
        "    #   cm = cm.numpy()[0]\n",
        "    #   print(img1.shape)\n",
        "    #   print(img2.shape)\n",
        "    #   print(cm.shape)\n",
        "    #   fig, ax = plt.subplots(1, 3, figsize=(10,10))\n",
        "    #   ax[0].imshow(img1)\n",
        "    #   ax[1].imshow(img2)\n",
        "    #   ax[2].imshow(cm)\n",
        "    #   break\n"
      ],
      "metadata": {
        "id": "G9K1e0LZHXdz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_custom(nn.Module):\n",
        "  def __init__(self, in_channel = 3, out_channel = 64, mid_channel = 32, dropout_prob = 0.5):\n",
        "    super(CNN_custom, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channel, mid_channel, kernel_size = 3, stride = 1, padding = 1), # 1 32\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(mid_channel, out_channel, kernel_size = 3, stride = 1, padding = 1), # 32 64\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.fc1 = nn.Linear(out_channel*7*7, 600) # out_channel*(image_H_after_layer2*image_W_after_layer2) 64*7*7 , 600\n",
        "    nn.init.xavier_uniform_(self.fc1.weight)\n",
        "    self.dropout1 = nn.Dropout(p = dropout_prob)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(600, 120)\n",
        "    self.dropout2 = nn.Dropout(p = dropout_prob)\n",
        "    self.fc3 = nn.Linear(120, 10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "      out = self.layer1(x)\n",
        "      out = self.layer2(out)\n",
        "      out = out.view(out.size(0), -1) ## flatting\n",
        "      out = self.fc1(out)\n",
        "      out = self.dropout1(out)\n",
        "      out = self.relu(out)\n",
        "      out = self.fc2(out)\n",
        "      out = self.dropout1(out)\n",
        "      out = self.relu(out)\n",
        "      out = self.fc3(out)\n",
        "      return out"
      ],
      "metadata": {
        "id": "Veyn3axIOfjA"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, mid_channels = None):\n",
        "    super().__init__()\n",
        "    if not mid_channels: mid_channels = out_channels\n",
        "    self.double_conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, mid_channels, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.BatchNorm2d(mid_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(mid_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.double_conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, mid_channels = None):\n",
        "    super().__init__()\n",
        "    self.maxpool_conv = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "        DoubleConv(in_channels, out_channels, mid_channels)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, mid_channels = None):\n",
        "    super().__init__()\n",
        "    self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "    self.conv = DoubleConv(in_channels, out_channels, mid_channels)\n",
        "  def forward(self, x1, x2):\n",
        "    x1  = self.up(x1)\n",
        "    diffX = (x2.size()[3] - x1.size()[3])\n",
        "    diffY = (x2.size()[2] - x1.size()[2])\n",
        "    x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
        "    x = torch.cat([x2, x1], dim = 1)\n",
        "    return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, mid_channels = None):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "Zsf2MvHKJ0W0"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self, n_channels, n_classes, bilinear = False):\n",
        "    super(UNet, self).__init__()\n",
        "    self.n_channels = n_channels\n",
        "    self.n_classes = n_classes\n",
        "    self.inc = (DoubleConv(n_channels, 64))\n",
        "    self.down1 = (Down(64, 128))\n",
        "    self.down2 = (Down(128, 256))\n",
        "    self.down3 = (Down(256, 512))\n",
        "    factor = 2 if bilinear else 1\n",
        "    self.down4 = (Down(512, 1024 // factor))\n",
        "    self.up1 = (Up(1024, 512 // factor))\n",
        "    self.up2 = (Up(512, 256 // factor))\n",
        "    self.up3 = (Up(256, 128 // factor))\n",
        "    self.up4 = (Up(128, 64))\n",
        "    self.outc = (OutConv(64, n_classes))\n",
        "\n",
        "  def forward(self, x1):\n",
        "    x11 = self.inc(x1)\n",
        "    x12 = self.down1(x11)\n",
        "    x13 = self.down2(x12)\n",
        "    x14 = self.down3(x13)\n",
        "    x15 = self.down4(x14)\n",
        "    x = x15\n",
        "    x = self.up1(x, x14)\n",
        "    x = self.up2(x, x13)\n",
        "    x = self.up3(x, x12)\n",
        "    x = self.up4(x, x11)\n",
        "    logits = self.outc(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "rsWbZnA0I2nz"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_channels = 3\n",
        "n_classes = 2\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet(n_channels = n_channels, n_classes = n_classes).to(device)\n",
        "input_data = torch.randn(2, 3, 512, 512)\n",
        "model = model.to(device)\n",
        "out = nn.Softmax(dim = 1)(model(input_data.to(device)))\n",
        "print(out.dtype)\n",
        "out = out.cpu().data.numpy()\n",
        "out = np.argmax(out, axis = 1).reshape(-1,1)\n",
        "print(input_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDNGs7XZTs6d",
        "outputId": "395fef9e-1bfb-4414-9634-bff80038d3cb"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.Size([2, 3, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_channels = 3\n",
        "n_classes = 2\n",
        "# input_data = torch.randn(1, n_channels, 128, 128).to(device)\n",
        "input_size = (2, 3, 512, 512)\n",
        "# summary(model, input_size = input_size)"
      ],
      "metadata": {
        "id": "WKuV74rkUqlD"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_channels = 3\n",
        "n_classes = 2\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNN_custom(in_channel = n_channels).to(device)\n",
        "input = torch.rand(2, 3, 28, 28)\n",
        "out = nn.Softmax(dim = 1)(model(input.to(device)))\n",
        "out = out.cpu().data.numpy()\n",
        "out = np.argmax(out, axis = 1).reshape(-1,1)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iszJ9XwEaPL_",
        "outputId": "51c076e6-e3e9-477d-9414-2cc9de60786a"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "oOY3PT9TiCzv"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.avg = 0\n",
        "        self.val = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "    def update(self, val, n = 1):\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.val = val\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "V0oSTJ7nB_Zg"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    metrics = {}\n",
        "#     y_pred = (y_pred > 0.5).astype(np.int32)  # Thresholding for binary classification\n",
        "#     y_true = y_true.ravel()  # Ensure y_true is flattened if necessary\n",
        "#     y_pred = y_pred.ravel()  # Ensure y_pred is flattened if necessary\n",
        "    metrics['accuracy']  = accuracy_score(y_true.ravel(), y_pred.ravel())\n",
        "    metrics['precision'] = precision_score(y_true, y_pred, average = 'macro', zero_division = 0)\n",
        "    metrics['recall']    = recall_score(y_true, y_pred, average = 'macro')\n",
        "    metrics['f1_score']  = f1_score(y_true, y_pred, average = 'macro')\n",
        "    metrics['iou'] = jaccard_score(y_true, y_pred, average = 'macro')\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "6qoiSwBUCP-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8"
      ],
      "metadata": {
        "id": "p1W_c1dXD7Jz"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(epochs, data_loader, model, criterion, grad_scaler, amp, optimizer,gradient_clipping, device, scheduler, epoch, global_step):\n",
        "    model.train()\n",
        "    criterion.train()\n",
        "    summary_loss = AverageMeter()\n",
        "    summary_acc = AverageMeter()\n",
        "    summary_iou = AverageMeter()\n",
        "    training_size = len(data_loader)\n",
        "    with tqdm(total = training_size, desc = f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
        "      for step, (img1, img2, mask_bin) in enumerate(data_loader):\n",
        "          # 1.-------  data img - float32, label - long ------- #\n",
        "          img1 = img1.to(device = device, dtype = torch.float32)\n",
        "          img2 = img2.to(device = device, dtype = torch.float32)\n",
        "          labels = mask_bin.to(device = device, dtype = torch.long)\n",
        "\n",
        "          # 2.------- model output and loss ------- #\n",
        "          with torch.autocast(device.type if device.type != 'cuda' else 'cpu', enabled = amp):\n",
        "            image = torch.cat((img1, img2), 1) # (2, 6, 512, 512)\n",
        "            output = nn.Softmax(dim = 1)(model(image.to(device))) # (2, 2, 512, 512)\n",
        "            output_1 = torch.argmax(output, dim = 1)\n",
        "            losses_c = criterion(output, labels)\n",
        "            losses_d = dice_loss(output.squeeze(1), labels.float(), multiclass=False)\n",
        "            losses = TverskyLoss(mode='multiclass', alpha = 0.6 , beta = 0.4 , gamma = 0.75)(output, labels)\n",
        "\n",
        "          # 3.------- backward ------- #\n",
        "          optimizer.zero_grad(set_to_none=True) # reset the gradients of all the model parameters before performing a backward pass\n",
        "          #losses.backward()\n",
        "          grad_scaler.scale(losses).backward() # backprogation with mixed precision\n",
        "          grad_scaler.unscale_(optimizer) # # Unscale gradients before applying any gradient manipulation (e.g., clipping)\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
        "\n",
        "          # 4.---- Perform the optimization step -----#\n",
        "          grad_scaler.step(optimizer)\n",
        "          grad_scaler.update()\n",
        "          # optimizer.step()\n",
        "\n",
        "          # 5. ---- lr_scheduling -----#\n",
        "          if scheduler is not None:\n",
        "              scheduler.step()\n",
        "\n",
        "          output = np.argmax(output.cpu().data.numpy(), axis=1)\n",
        "          pbar.update(img1.shape[0])\n",
        "          global_step += 1\n",
        "\n",
        "          # 6.---- matric calculation -----#\n",
        "          metrics = calculate_metrics(labels.cpu().data.numpy().reshape(-1, 1), output.reshape(-1, 1))\n",
        "          summary_acc.update(metrics['accuracy'].item(), BATCH_SIZE)\n",
        "          summary_loss.update(losses.item(), BATCH_SIZE)\n",
        "          pbar.set_postfix(loss = summary_loss.avg,  acc = summary_acc.avg, iou = summary_iou.avg)\n",
        "      return summary_loss"
      ],
      "metadata": {
        "id": "fhml9qnK9hVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def eval_fn(dataloader, model, criterion, device, amp):\n",
        "    model.eval()\n",
        "    criterion.eval()\n",
        "    summary_loss = AverageMeter()\n",
        "    summary_acc = AverageMeter()\n",
        "    summary_iou = AverageMeter()\n",
        "    summary_f1 = AverageMeter()\n",
        "    summary_precision = AverageMeter()\n",
        "    summary_recall = AverageMeter()\n",
        "    summary_c = AverageMeter()\n",
        "    summary_d = AverageMeter()\n",
        "    dice_score = 0\n",
        "    with torch.no_grad():\n",
        "        tk0 = tqdm(dataloader, total = len(dataloader), desc='Validation round', unit='batch', leave = False)\n",
        "        for step, (img1, img2, mask_bin) in enumerate(tk0):\n",
        "            #img1 = img1.to(device = device, dtype = torch.float32, memory_format = torch.channels_last)\n",
        "            #img2 = img2.to(device = device, dtype = torch.float32, memory_format = torch.channels_last)\n",
        "            img1 = img1.to(device = device, dtype = torch.float32)\n",
        "            img2 = img2.to(device = device, dtype = torch.float32)\n",
        "            labels = mask_bin.to(device=device, dtype = torch.long)\n",
        "            with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
        "              # output = model(img1, img2)\n",
        "              # print(output.shape)\n",
        "              # print(type(output))\n",
        "              image = torch.cat((img1, img2), 1)\n",
        "              output = nn.Softmax(dim = 1)(model(image.to(device)))\n",
        "              output_1 = torch.argmax(output, dim=1)  # Convert softmax output to binary (2, 512, 512)\n",
        "              #losses_c = criterion(output.squeeze(1), labels.float())\n",
        "              losses_c = criterion(output, labels)\n",
        "              #losses_d = dice_loss(output.squeeze(1), labels.float(), multiclass=False)\n",
        "              #losses_d = DiceLoss(mode='multiclass')(output, labels)\n",
        "              losses_d = TverskyLoss(mode='multiclass', alpha = 0.6 , beta = 0.4 , gamma = 0.75)(output, labels)\n",
        "              #losses = criterion(output.squeeze(1), labels.float()) + dice_loss(output.squeeze(1), labels.float(), multiclass=False)\n",
        "              #losses = criterion(output, labels) + DiceLoss(mode='multiclass')(output, labels)\n",
        "              losses = TverskyLoss(mode='multiclass', alpha = 0.6 , beta = 0.4 , gamma = 0.75)(output, labels)\n",
        "              output1 = output.argmax(dim=1, keepdim=True)\n",
        "              labels1 = labels.unsqueeze(1)\n",
        "              dice_score += dice_coeff(output1, labels1, reduce_batch_first = False)/max(len(dataloader), 1)\n",
        "            #metrics = calculate_metrics(labels.cpu().data.numpy(), output.squeeze(1).cpu().data.numpy())\n",
        "              output = np.argmax(output.cpu().data.numpy(), axis = 1)\n",
        "            metrics = calculate_metrics(labels.cpu().data.numpy().reshape(-1, 1), output.reshape(-1, 1))\n",
        "            summary_acc.update(metrics['accuracy'].item(), BATCH_SIZE)\n",
        "            summary_loss.update(losses.item(), BATCH_SIZE)\n",
        "            summary_c.update(losses_c.item(), BATCH_SIZE)\n",
        "            summary_d.update(losses_d.item(), BATCH_SIZE)\n",
        "            summary_iou.update(metrics['iou'].item(), BATCH_SIZE)\n",
        "            summary_f1.update(metrics['f1_score'].item(), BATCH_SIZE)\n",
        "            summary_precision.update(metrics['precision'].item(), BATCH_SIZE)\n",
        "            summary_recall.update(metrics['recall'].item(), BATCH_SIZE)\n",
        "            tk0.set_postfix(loss = summary_loss.avg, loss_c = summary_c.avg, loss_d = summary_d.avg, acc = summary_acc.avg,\n",
        "                            iou = summary_iou.avg, f1_score = summary_f1.avg, precision = summary_precision.avg, recall = summary_recall.avg)\n",
        "            if step % 35 == 0:\n",
        "                visualize_result(img1.cpu().numpy(), img2.cpu().numpy(), labels.cpu().data.numpy(), output)\n",
        "    return dice_score, summary_loss, summary_c, summary_d, summary_acc, summary_iou, summary_f1, summary_precision, summary_recall"
      ],
      "metadata": {
        "id": "577_hElBFRV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = {\n",
        "    't_loss': [],\n",
        "    't_acc': [],\n",
        "    't_iou': [],\n",
        "    't_f1': [],\n",
        "    't_precision': [],\n",
        "    't_recall': [],\n",
        "    't_c': [],\n",
        "    't_d' : [],\n",
        "    'd_score' : [],\n",
        "    'v_loss': [],\n",
        "    'v_acc': [],\n",
        "    'v_iou': [],\n",
        "    'v_f1': [],\n",
        "    'v_precision': [],\n",
        "    'v_recall': [],\n",
        "    'v_c': [],\n",
        "    'v_d': []\n",
        "}\n",
        "def run(dataset, trainloader, valloader, model, epochs, learning_rate, weight_decay, save_checkpoint, amp, momentum, gradient_clipping, n_classes, **kwargs):\n",
        "    global_step = 0\n",
        "    training_size = len(trainloader)\n",
        "    BATCH_SIZE = 2\n",
        "    criterion = nn.CrossEntropyLoss() if n_classes > 1 else nn.BCEWithLogitsLoss() #criterion = FocalTverskyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate, weight_decay = weight_decay,  foreach=True)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts( optimizer, T_0 = 2, T_mult = 2, eta_min = 1e-5)\n",
        "    grad_scaler = torch.cuda.amp.GradScaler(enabled = amp)\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        # -------- train --------- #\n",
        "        train_loss, train_c, train_d, train_acc, train_iou, train_f1, train_precision, train_recall = train_fn(epochs, trainloader, model, criterion, grad_scaler, amp,\n",
        "        optimizer, gradient_clipping, device, scheduler = scheduler, epoch = epoch, global_step = global_step)\n",
        "\n",
        "        # -------- eval & lr_scheduling --------- #\n",
        "        dice_score, val_loss, val_c, val_d, val_acc, val_iou, val_f1, val_precision, val_recall  = eval_fn(valloader, model, criterion, device, amp)\n",
        "#         scheduler.step(dice_score)\n",
        "        history['v_loss'].append(val_loss)\n",
        "        history['v_c'].append(val_c)\n",
        "        history['v_d'].append(val_d)\n",
        "        history['v_acc'].append(val_acc)\n",
        "        history['v_iou'].append(val_iou)\n",
        "        print(\"\"\"\n",
        "        EPOCH {}:\n",
        "        TRAIN_LOSS {}\n",
        "        TRAIN_ACC {}\n",
        "        \"\"\".format(epoch, train_loss.avg, train_acc.avg, train_c.avg, train_d.avg, train_iou.avg, train_f1.avg, train_precision.avg, train_recall.avg, dice_score, val_loss.avg, val_c.avg, val_d.avg, val_acc.avg, val_iou.avg, val_f1.avg, val_precision.avg, val_recall.avg))\n",
        "\n",
        "        if save_checkpoint:\n",
        "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
        "            checkpoint = {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }\n",
        "            torch.save(checkpoint, str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))"
      ],
      "metadata": {
        "id": "WNOaMNxXFT3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-6\n",
        "save_checkpoint = True\n",
        "amp = True\n",
        "momentum = 0.999\n",
        "gradient_clipping = 1.0\n",
        "# n_classes = 1\n",
        "n_classes = 2\n",
        "# checkpoint_file = 'checkpoint_epoch9.pth'\n",
        "load_checkpoint = False\n",
        "# if load_checkpoint:\n",
        "#     checkpoint = torch.load(str(dir_checkpoint / checkpoint_file))\n",
        "#     start_epoch = checkpoint['epoch'] + 1  # Start from the next epoch\n",
        "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#     run(dataset, trainloader, valloader, model, epochs, learning_rate, weight_decay, save_checkpoint, amp, momentum, gradient_clipping, n_classes)\n",
        "run(dataset, trainloader, valloader, model, epochs, learning_rate, weight_decay, save_checkpoint, amp, momentum, gradient_clipping, n_classes)"
      ],
      "metadata": {
        "id": "Xcl_Au2gFV2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_result(image1, image2, true_mask, predict_mask):\n",
        "    nrows = min(7, image1.shape[0])  # Ensure we don't exceed the batch size\n",
        "    ncols = 4\n",
        "    figsize = (20, 10)  # Adjust figsize based on the number of rows and columns\n",
        "    fig, ax = plt.subplots(nrows = nrows, ncols = 4, figsize = figsize)\n",
        "#     print(predict_mask.shape)\n",
        "#     print(type(predict_mask))\n",
        "    for i in range(nrows):\n",
        "        ax[i, 0].imshow(image1[i,...].transpose(2, 1, 0))\n",
        "        ax[i, 1].imshow(image2[i,...].transpose(2, 1, 0))\n",
        "        ax[i, 2].imshow(true_mask[i,...])\n",
        "        ax[i, 3].imshow(predict_mask[i,...])\n",
        "        ax[i, 0].set_title('image1')\n",
        "        ax[i, 1].set_title('image2')\n",
        "        ax[i, 2].set_title('ground_truth')\n",
        "        ax[i, 3].set_title('predict mask')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "o0ToHLK2IAfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(10))))\n",
        "model.eval()\n",
        "\n",
        "# Predict the masks for the val data\n",
        "masks_pred = []\n",
        "with torch.no_grad():\n",
        "    for img1, img2,label in valloader:\n",
        "        img1 = img1.to(device = device, dtype = torch.float32, memory_format = torch.channels_last)\n",
        "        img2 = img2.to(device = device, dtype = torch.float32, memory_format = torch.channels_last)\n",
        "        outputs = model(img1, img2)\n",
        "        visualize_result(img1.cpu().numpy(), img2.cpu().numpy(), labels.cpu().data.numpy(), output.cpu().data.numpy())\n",
        "\n"
      ],
      "metadata": {
        "id": "7prFu3S1FXHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_loss = [x.avg for x in history['t_loss']]\n",
        "t_acc = [x.avg for x in history['t_acc']]\n",
        "t_iou = [x.avg for x in history['t_iou']]\n",
        "t_f1 = [x.avg for x in history['t_f1']]\n",
        "t_precision = [x.avg for x in history['t_precision']]\n",
        "t_recall = [x.avg for x in history['t_recall']]\n",
        "\n",
        "v_loss = [x.avg for x in history['v_loss']]\n",
        "v_acc = [x.avg for x in history['v_acc']]\n",
        "v_iou = [x.avg for x in history['v_iou']]\n",
        "v_f1 = [x.avg for x in history['v_f1']]\n",
        "v_precision = [x.avg for x in history['v_precision']]\n",
        "v_recall = [x.avg for x in history['v_recall']]\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(3, 2, figsize=(15, 15))\n",
        "\n",
        "# Plot Loss\n",
        "axs[0, 0].plot(t_loss, label='Train Loss')\n",
        "axs[0, 0].plot(v_loss, label='Validation Loss')\n",
        "axs[0, 0].set_title('Loss')\n",
        "axs[0, 0].set_xlabel('Epoch')\n",
        "axs[0, 0].set_ylabel('Loss')\n",
        "axs[0, 0].legend()\n",
        "\n",
        "# Plot Accuracy\n",
        "axs[0, 1].plot(t_acc, label='Train Accuracy')\n",
        "axs[0, 1].plot(v_acc, label='Validation Accuracy')\n",
        "axs[0, 1].set_title('Accuracy')\n",
        "axs[0, 1].set_xlabel('Epoch')\n",
        "axs[0, 1].set_ylabel('Accuracy')\n",
        "axs[0, 1].legend()\n",
        "\n",
        "# Plot IoU\n",
        "axs[1, 0].plot(t_iou, label='Train IoU')\n",
        "axs[1, 0].plot(v_iou, label='Validation IoU')\n",
        "axs[1, 0].set_title('IoU')\n",
        "axs[1, 0].set_xlabel('Epoch')\n",
        "axs[1, 0].set_ylabel('IoU')\n",
        "axs[1, 0].legend()\n",
        "\n",
        "# Plot F1 Score\n",
        "axs[1, 1].plot(t_f1, label='Train F1 Score')\n",
        "axs[1, 1].plot(v_f1, label='Validation F1 Score')\n",
        "axs[1, 1].set_title('F1 Score')\n",
        "axs[1, 1].set_xlabel('Epoch')\n",
        "axs[1, 1].set_ylabel('F1 Score')\n",
        "axs[1, 1].legend()\n",
        "\n",
        "# Plot Precision\n",
        "axs[2, 0].plot(t_precision, label='Train Precision')\n",
        "axs[2, 0].plot(v_precision, label='Validation Precision')\n",
        "axs[2, 0].set_title('Precision')\n",
        "axs[2, 0].set_xlabel('Epoch')\n",
        "axs[2, 0].set_ylabel('Precision')\n",
        "axs[2, 0].legend()\n",
        "\n",
        "# Plot Recall\n",
        "axs[2, 1].plot(t_recall, label='Train Recall')\n",
        "axs[2, 1].plot(v_recall, label='Validation Recall')\n",
        "axs[2, 1].set_title('Recall')\n",
        "axs[2, 1].set_xlabel('Epoch')\n",
        "axs[2, 1].set_ylabel('Recall')\n",
        "axs[2, 1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tFUTAkCJFYzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define tensors\n",
        "x = torch.tensor(3., requires_grad=True)\n",
        "y = torch.tensor(4., requires_grad=True)\n",
        "z = 2*x*y + 3\n",
        "\n",
        "# Visualize the graph\n",
        "z.backward()\n",
        "print(x.grad)\n",
        "print(y.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZx4B0SBVUuc",
        "outputId": "fbe414cd-7bb2-4e34-cc3e-f56ece155d15"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.)\n",
            "tensor(6.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, custom_param):\n",
        "        super(CustomLayer, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.bias = None  # Optionally, describe custom parameters\n",
        "        self.custom_param = custom_param\n",
        "        self.reset_parameters()  # Example: Initialize weights and optional parameters\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Init codes for weights and optional parameters\n",
        "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Custom computation on input 'x'\n",
        "        x = F.linear(x, self.weight, self.bias)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RraKjaHfj4zr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}